<html>
    <head>
        <link id="pagestyle" rel="stylesheet" type="text/css" href="../css/carboniferous.css">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
        </script>
        <script type="text/javascript"
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="application/javascript" src="../js/toggler.js"></script>
    </head>
    
    <body>
        <div id="togglerbody" style="text-align:center">
            <button id="toggler"> repaint </button>
            <h1 style="margin: 0 auto"><a href="../index.html"><div id="title">Samuel Tenka</div></a></h1>
        </div>

        $\newcommand{\NN}{\mathbb{N}}$
        $\newcommand{\ZZ}{\mathbb{Z}}$
        $\newcommand{\RR}{\mathbb{R}}$
        $\newcommand{\CC}{\mathbb{C}}$

        
<p>
<p>
<p>
<h2>  Foundations of Statistical Mechanics </h2>
<p>
    Statistical mechanics helps us predict the behavior of many-component
physical systems via the technique of <em>averaging</em>.  Specifically, the recipe to
predict a measurement of a system "at temperature $T$" is as follows.  We write
down a certain probability distribution over the system's configuration space;
the density at a configuration $x$ with energy $E(x)$ is $p(x) \propto
\exp(-E(x)/T)$.  Note that this distribution is abstract: it is not clear what
randomness, if any, it corresponds to.  For each configuration $x$, we compute
the number $f(x)$ that the measurement would yield.  Then our prediction is the
expectation of $f(x)$ with respect to the aforementioned distribution.
<p>
    For example, when $f=E$, the recipe helps us predict the system's total
energy as a function of its temperature; we may thus compute the heat
capacities of systems such as crystals, molecular gases, and blackbody
radiation.  In fact, for a gas with very low pressure $p$ (force per area) and
very low density $n$ (particles per volume), the recipe predicts that $T =
p/n$.  It was a priori unclear how to measure temperature; this result about
gases helps us to calibrate our thermometers: the appropriate value of $T$ for
a different system will be the $p/n$ of a low-pressure, low-density gas in
equilibrium with the system.  
<p>
    Our goal is to provide intuition for this recipe.  We will discuss two
related questions.  <b>First</b>, why is measurement related to an average at all?
<b>Second</b>, why does the average have the specific weights $\exp(-E(x)/T)$?
These questions are difficult and we will not succeed beyond offering some
partial intuition.  Indeed, there does not seem to be consensus even on the
basic question of what physical variation the aformentioned distribution 
fundamentally represents.
Various texts interpret the distribution as that of many temporally-separated
measurements over long times as the system evolves (<span style="font-variant: small-caps";>Halmos</span style="font-variant: small-caps";>), or of many small
parts of the overall system (<span style="font-variant: small-caps";>Khinchin</span style="font-variant: small-caps";>), or of many possible initial
conditions of the system (<span style="font-variant: small-caps";>Feynman</span style="font-variant: small-caps";>).   
<p>
<h3>  Boltzmann's Law  </h3>
<p>
<h4>  Extensive Properties </h4>
<p>
    Imagine two parcels of matter very far from each other.  Their joint
probability is a product, and their joint energy is a sum.  Therefore, if we
are to assign probabilities to system configurations, and if we insist that
these probabilities are functions only of energy, then the probability must be
exponential in the energy.  Thus, $\mathcal{P}(x) \propto \exp(-\beta E(x))$
for some constant $\beta$ characteristic of the system's temperature.  We only
used that energy is extensive (and later we will use that total energy is
conserved); we could have spoken of volume, charge, angular momentum, or any
other extensive quantity that is conserved in a laboratory room.  More
generally, if we wish to assign probabilities that depend only on a finite set
of extensive quantities (say volume $V$, energy $E$, and charge $C$) then the
probability must be of form $\mathcal{P}(x) \propto \exp(-\alpha V(x) -\beta
E(x) -\gamma C(x))$. 
<p>
<h4>  The Natural Measure </h4>
<p>
<h3>  Averages or Concentration? </h3>
<p>
<h4>   </h4>
<p>
<h4>   </h4>
<p>
<h3>  Fluctuations in Time </h3>
<p>
<h4>  Liouville's Theorem </h4>
<p>
<h4>  Can Dynamics get Stuck?   </h4>
<p>
<h3>  References </h3>
<p>
    <b>Batterman</b>   ---  <em>Why Equilibrium Statistical Mechanics Works</em>        ---  1998
<p>
    <b>Feynman</b>     ---  <em>Lectures on Statistical Mechanics</em>                  ---  1981
<p>
    <b>Khinchin</b>    ---  <em>Mathematical Foundations of Statistical Mechanics</em>  ---  1960
<p>
    <b>Penrose</b>     ---  <em>Foundations of Statistical Mechanics</em>               ---  1979
<p>
    <b>Truesdell</b>   ---  <em>Six Lectures on Natural Philosophy</em>                 ---  1966
<p>
<p>
    </body>
</html>
