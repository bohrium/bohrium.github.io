<html>
    <head>
        <link id="pagestyle" rel="stylesheet" type="text/css" href="../css/carboniferous.css">
        <link id="pagestyle" rel="stylesheet" type="text/css" href="./aside.css">
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
        </script>
        <script type="text/javascript"
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="application/javascript" src="../js/toggler.js"></script>
    </head>
    
    <body>
        <div id="togglerbody" style="text-align:center">
            <button id="toggler"> repaint </button>
            <h1 style="margin: 0 auto"><a href="../index.html"><div id="title">Samuel Tenka</div></a></h1>
        </div>

        $\newcommand{\NN}{\mathbb{N}}$
        $\newcommand{\ZZ}{\mathbb{Z}}$
        $\newcommand{\RR}{\mathbb{R}}$
        $\newcommand{\CC}{\mathbb{C}}$
        $\newcommand{\pr}{^\prime}$
        $\newcommand{\prpr}{^{\prime\prime}}$
        $\newcommand{\wrap}[1]{\left(#1\right)}$

        
<p>
<h2>  Precis of EECS 437 </h2>
<p>
$\newcommand{\sfA}{{\mathsf{A}}}$
$\newcommand{\sfH}{{\mathsf{H}}}$
$\newcommand{\sfr}{{\mathsf{r}}}$
$\newcommand{\sfx}{{\mathsf{x}}}$
$\newcommand{\sfy}{{\mathsf{y}}}$
$\newcommand{\sfz}{{\mathsf{z}}}$
$\newcommand{\Ee}{{\mathbb{E}}}$
$\newcommand{\Rr}{{\mathbb{R}}}$
$\newcommand{\aA}{{\mathcal{A}}}$
$\newcommand{\fF}{{\mathcal{F}}}$
$\newcommand{\hH}{{\mathcal{H}}}$
$\newcommand{\lL}{{\mathcal{L}}}$
$\newcommand{\nN}{{\mathcal{N}}}$
$\newcommand{\pP}{{\mathcal{P}}}$
$\newcommand{\xX}{{\mathcal{X}}}$
$\newcommand{\yY}{{\mathcal{Y}}}$
$\newcommand{\sto}{\rightsquigarrow}$
<p>
<h4>  Hallo </h4>
Here is an incomplete --- and, I bet, sometimes incorrect --- list of musings
on some class topics.  The point is aid digestion by saying old ideas in new
ways.
I believe in depth perception through binocular vision.
<p>
<h3>  Decision Theory </h3>
<h4>  Two Approaches to Uncertainty: Bayes, Adversary </h4>
<h5>  Dramatis Personae </h5>
Let's model decision-making in the face of uncertainty.  We're uncertain about
some aspect \(\sfH\) of the world.  We wish we knew \(\sfH\) because we've
gotta decide some action \(\sfA\) to take, and depending on \(\sfH\) different
actions may be "best".  That is, our overall reward \(\sfr\) depends on both
\(\sfA\) and \(\sfH\).  Helpfully, a clue \(\sfy\) tells us (noisily)
about
\(\sfH\).  Now: <em>how do we choose \(\sfA\) upon observing \(\sfy\)?</em>
<p>
So \(\sfy\) depends on \(\sfH\); \(\sfA\) depends (via a strategy we choose) on
\(\sfy\); and \(\sfr\) depends on \(\sfA,\sfH\).  Let's model these
dependencies as probabilistic; the data flows like:
\[
\sfy\sim p(\cdot;\sfH)
\qquad
\sfA\sim s(\cdot;\sfy)
\qquad
\sfr\sim r(\cdot;\sfA,\sfH)
\]
As engineering specs we're given a probability model \(p\) and reward model
\(r\).  We must design a <b>strategy</b> \(s\) that says, for each value of
\((A,y)\), how likely we are to set \(\sfA=A\) upon observing \(\sfy=y\).<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160
Why do we allow \(\sfA\) to depend probabilistically on \(\sfy\)?  Answer:
we'll encounter situations where <em>bluffing</em> is important.
</span></span>
We'll care about rewards only through their expected values, so we can assume
without loss that \(\sfr\) is a deterministic function of \(\sfA,\sfH\).
<p>
<p>
<p>
<p>
<p>
We want to choose \(s\) to get high rewards \(\sfr\) "on average".  How do we
quantify this for a given candidate \(s\)?  Well, <b>if we knew</b> that \(\sfH=H\)
then we could compute our expected reward:
\[
R_s(H) \triangleq
\Ee_{\sfy\sim p(\cdot;H)}\,
\Ee_{\sfA\sim s(\cdot;\sfy)}\,
\Ee_{\sfr\sim r(\cdot;\sfA,\sfH)}\,\,
\sfr
\]
<p>
we have probability distributions respect to \(\sfy,\sfA\) but not \(\sfH\), so
we get a reward function \(R_s:\hH\to\Rr\).
<p>
In other words, two methods for collapsing (aggregating) a bunch of values, one
for each \(H\), are: take the MIN (worst-case) or take the AVERAGE with respect
to some distribution.  That is, we evaluate the quality of a strategy \(s\) as
\(\min_\sfH{}R_s(\sfH)\) or as \(\Ee_{\sfH\sim\pi}R_s(\sfH)\).
These are two philosophically different ways of handling
uncertainty.
<p>
<h5>  Bayes vs Adversarial </h5>
In the Bayes setup, we assume known a distribution \(\pi\in\pP^\hH\) that we
use as a prior on \(\hH\).  We want to \(\Ee_{\sfH\sim\pi}R_s(\sfH)\).
<p>
In the Adversarial setup, we maximize \(\min_\sfH{}R_s(\sfH)\).
<p>
<h5>  Likelihood Ratios </h5>
<p>
<p>
<h5>  Relationship via Duality </h5>
<p>
<h4>  Pictures for Binary and Related Cases </h4>
<p>
<h5>  2 Hypotheses and 2 Actions </h5>
<p>
When \(\hH=\{H_0,H_1\}\) and \(\aA=\{A_0,A_1\}\) are both size-\(2\) sets, then
(either some \(A\) is best for all \(H\)s and we are done or) we can by
re-labeling assume that \(A_i\) is best under \(H_i\).  We may regard \(A_i\)
as the action of "guessing that the situation is \(H_i\)".  It's traditional to
put \(H_1\) as "something happening"<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160e.g. a certain stratum witnessing a
certain crinoid genus's extinction, a Higgs decay at the LHC, a vaccine being
effective in trials, there existing a typo in <em>Deathly Hallows</em>, etc</span></span> and
\(H_0\) as a more neutral alternative; our
<em>language will reflect this</em>
tradition but there's of course nothing in our math that treats \(H_1,H_0\)
asymmetrically.
<p>
Any strategy \(s:\yY\sto\aA\) then induces two failure rates
\(F_i\triangleq{}P(s(\sfy)\neq{}A_i;H_i)\), namely the rate \(F_1\) of missed
detection and the rate \(F_0\) of false alarm.  We know that thresholding on
likelihood ratios (with a weighted coin flip in case of a tie) gives an good
family of strategies; this draws a <em>curve</em> in the \((F_0,F_1)\)-plane.
<p>
Any choice of cost structure simply shifts and stretches that square into some
axis-aligned rectangle in the cost-cost plane.  If additionally we choose a
prior then we may transform again to the expectedcost-expectedcost plane by
scaling each axis by the probability of its associated hypothesis.
Under a minimax adversary we want to choose the all-equal-costs point.
Under a Bayesian framework we want to maximize the expectation-of-costs
functional and thus in the expectedcost-expectedcost plane find a point at
which there is all-equal-slopes.
<p>
See this beautiful duality!
<p>
Note: the area within the curve is the AUROC, the probability of correct
binary ranking.
<p>
<h5>  3 Hypotheses and 2 Actions </h5>
Now our plot is a product of \(3\) simplices each with \(2\) corners.  It's
three dimensional.
<p>
The reachable region is a convex set containing the two matching corners
\((0,0,0),(1,1,1)\).
<p>
<h5>  2 Hypotheses and 3 Actions </h5>
Now our plot is a product of \(2\) simplices each with \(3\) corners.  It's
four dimensional.  It's a product of two triangles.  We can imagine a
triangular prism growing in height from height 0: corresponding to corners of
the non-obvious triangle are: the initial triangle, the final top face, and the
final bottom face.
<p>
The reachable region is a convex set containing the \(3\) matching corners
\((a,a),(b,b),(c,c)\).  That is, it contains the triangle where one corner of
the initial stretches to become a diagonal line segment on an opposite
rectangle of the final prism.
<p>
A different embedding into our space-and-time imagination is this.
The matching corners are a spatial triangle in a single instant.  How might
we imagine the other \(6\) corners?  Well, they divide into three opposing
pairs \((a,b),(b,a);\cdots\).  Embed \((a,b),(b,a)\) on the midpoint of the
\((a,a)-(b,b)\) edge, but shifted forward and backward in time.
<p>
<h5>  3 Hypotheses and 3 Actions </h5>
<p>
Here we in general run into a kind of voting paradox, to do with the fact
that the number (3 factorial) of rankings on \(A\) exceeds the number (3) of
\(H\)s.  Let us restrict focus to an especially simple case where the reward
matrix is the identity.
<p>
A full plot is a product of \(3\) simplices each with \(3\) corners.  It's six
dimensional.
<p>
<p>
<p>
<p>
<p>
<h4>  Entropy </h4>
<p>
<h3>  Estimation and Information Geometry </h3>
<p>
<h4>  KL Geometry </h4>
Estimation fits into our starting setup with \(\hH\) and \(\aA\) both equal to
some continuous parameter space \(\xX\), and with \(r\) some notion of
closeness.  It thus behooves us to analyze this space \(\xX\) of distributions
on \(\yY\) geometrically.  The key notion of different-ness between two
distributions is the <b>KL Divergence</b>
\[
    D(p:q) = \Ee_{y\sim p}[\log(p(y)/q(y))]
\]
that measures our average excess surprise when we expect samples from \(q\) but
instead get samples from \(p\).  This divergence is <b>not symmetric</b>!  Also,
when the right-hand-side is not defined, we define the value to be infinite.
<p>
<h4>  Classical Quadratic Theory of Estimation </h4>
<p>
<h4>  Cramer-Rao Bound and Bias-Variance Tradeoff </h4>
<p>
<h4>  Multiple Parameters </h4>
Here are some interesting geometric effects when \(\xX\) has high dimension \(m\)
(such as \(3\)).
<p>
<h5>  Shrinkage </h5>
Take the standard Gaussian likelihood model: \(\sfy=x+\sfz\) where
\(\sfz\sim\nN(0,I)\).  The data of an estimator is the data of a vector field
\(v(y)\) inducing estimate \(\hat\sfx=y-v(y)\).  Then a leading approximation
for the square loss at \(x\) is
\[
    1 - 2 \text{div} v + \|v\|^2
\]
This approximation is valid when \(\text{div}v\) and \(v\cdot{}v\) both change
very slowly (compared to the natural length scale of \(sfz\)'s spread).  We
improve on the obvious estimator when
\[
\text{div}v\geq\|v\|^2/2
\]
The key is that the LHS has a chance of scaling with the dimension
to overwhelm the RHS.  Even for constant \(\|v\|\) (imagine a field of
unit-vectors), there's enough angular elbow room so that we can arrange for
divergences everywhere to be positive simultaneously.
((It's not enough to just argue by scaling that we can
make the RHS arbitrarily small by vertically scaling v, since we want an
improvement at every \(x\) <em>simultaneously</em>.))
<p>
For example, suppose \(\vec v(y) = u(\|y\|) (\vec y/\|y\|)\) is radial.  Then
(choose a basis at \(y\) that includes \(y/\|y\|\)) the divergence has a radial
term \(u\pr\) and \(m-1\) angular terms \(u/\|y\|\).  This angular contribution
represents that the surface area of radius-\(r\) balls decreases as \(r\)
decreases, by \(\text{SA}\pr/\text{SA}=(m-1)/r\).
Anyway, combining with \(\|v\|^2=u^2\) let's write a condition for improvement:
\[
    u\pr + ((m-1)/r) u \geq u^2/2
\]
Under the ansatz \(u(r)=\alpha r^p\), this condition reads \((p+m-1) r^{p-1}
\geq (\alpha/2) r^{2p}\), or \(r^{p+1}\leq 2/(\alpha(p+m-1))\).  Pay special
attention to \(p=1,-1\), which are MAP estimators respectively for Gaussian and certain
<em>unnormalized</em>-powerlaw priors.  (And, even better,
<em>Least-Squares-under-Posterior estimators for that Gaussian).</em>
For example, setting \(u(r)=\alpha r\) (the gaussian prior case) satisfies this
bound when \(m\geq \alpha r^2/2\), that is for \(r\ll \sqrt{m/\alpha}\).  We'd
like to modify this to have the same behavior.
<p>
An elegant way to get both behaviors is \(u(r) = \alpha r/(R^2+r^2)\), which for
\(R\gg 1\) much larger that \(z\)'s noise scale and \(\alpha\ll 1\) verifies
the small derivative assumptions on \(\text{div}v\) and \(v^2\).
<p>
This is a (regularized) <b>James Stein estimator</b>.  It is MAP for a certain
<em>unnormalized</em>-Cauchy prior.
<p>
<p>
<p>
<p>
<p>
<p>
<h3>  Asymptotics </h3>
<h3> ! </h3>
<h3> ! </h3>
<p>
<h3>  Inference Methods: Stochastic Approximation </h3>
<h3> ! </h3>
<h3> ! </h3>
<p>
<h3>  Special Topics </h3>
<h4>  Universal Featurization </h4>
<h4>  Diffusion Models </h4>
<p>
<p>
<h3>  Appendix: Math Helpers </h3>
Here are some math concepts we'll use.  Plus, as a <em>lagniappe</em>, some we won't.
<p>
<h4>  Basic Linear Algebra </h4>
<h4> ! </h4>
<h4> ! </h4>
<h5>  Convexity and Duality </h5>
<p>
<h4>  Basic Calculus </h4>
<h5>  Jacobian, Gradient </h5>
<h5>  Hessian, Laplacian </h5>
<h5>  Aside on Gradient Descent </h5>
<h5>  Connections and Curvature </h5>
<p>
<h5>  Topology </h5>
<p>
Let's think about subsets of the Cartesian plane.  A collection of equations
like \(x=y\) or \(x^2+y^2=1\) or \(\max(1,x^2+y^2)=1\) determines a plane
subset of simultaneous solutions.  More precisely, we require each equation to
read \(f(x,y)=0\) where \(f\) is some <b>continuous</b> function to the reals.  Call
a subset that arises in this way <span style="font-variant: small-caps">Clean</span>.  The <span style="font-variant: small-caps">Clean</span> subsets are closed under
arbitrary intersection.  And by multiplication they are also closed under
finitary union.
<p>
<p>
<p>
The notions we'll use are <b>closure</b>.
<p>
Intuitively, the closed sets are those cut out by sets of equations such as
<p>
<h6>  Compactness </h6>
Suppose an infinite family of closed sets has empty intersection.  One way this
can happen is if a finite sub-family has empty intersection.  In this case, we
say the infinitary intersection is empty for <span style="font-variant: small-caps">silly reasons</span>.
A set is <b>compact</b> when every empty infinitary intersection of closed sets is
empty for silly reasons.
The significance of compactness comes from two consequences: (a) that compact
sets push forward under continuous maps to compact sets; (b) that
<p>
<p>
<h4>  Basic Probability </h4>
<h5>  Overview </h5>
How might we math-ify "uncertainty"?  If we know how to reason about variables
of type \(X\), how do we reason about variables of type
\(\texttt{randomvaluein}\,X\)?<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160I use this programming-ish language on purpose.
The \(\texttt{randomvaluein}\) is a type constructor, just as
\(\texttt{listof}\) and \(\texttt{etthernullor}\) and
\(\texttt{dictfromstringsto}\) and \(\texttt{predicateonsubsetsof}\) are type
constructors.</span></span>
<p>
We do so by generalizing evaluation of functions \(f:X\to\Rr\): a value
\(x\in{X}\) is "as good as" the map \(\epsilon_x\) that takes \(f\) as input
and returns \(f(x)\).  By "as good as" I mean that different \(x\)s lead to
different \(\epsilon_x\)s, so no information is lost.
Can we recognize the \(\epsilon_x\)s among all functions of type \((X\to
\Rr)\to\Rr\)?  Yes: they are precisely those that commute with all
functions \(t:\Rr\to\Rr\) in the sense that \(\epsilon(t\circ f) =
t(\epsilon(f))\).  We could as well have allowde \(t\) to take several
arguments and demand that
\(\epsilon((x\mapsto{t(f(x),\cdots,g(x))}))=t(\epsilon(f),\cdots,\epsilon(g))\);
this any-ary constraint is equivalent to the unary constraint and is intellectually
rewarding.  Examples:
When \(t(y)=c\) is constant: \(\epsilon((x\mapsto c))=c\) <b>normalization</b>.
One way to generalize the constants rule is by going to one higher degree (constant
plus linear term):
When \(t(y,y\pr)=5+y+6y\pr\): \(\epsilon(5+f+6g)=5+\epsilon(f)+6\epsilon(g)\) <b>linearity</b>.
When \(t(y)=(0\,\text{if}\,5\leq{y}\leq{8}\,\text{else}\,1)\) is a bounds check:
when \(f\) maps into \([5,8]\) then \(\epsilon(f)\) is in that same interval (<b>positivity</b>).
This generalizes the constancy rule.
In short:
\[
X \cong \{\epsilon:(X\to\Rr)\to\Rr\,\text{that commute with all}\,t\}
\]
<p>
Let's relax this by asking just for the affine and positivity part of
commutativity: what do we get if we demand only the normalization and linearity
rules (for this paragraph, suppose for simplicity that \(X\) is finite
nonempty):
\[
??? \cong \{\epsilon:(X\to\Rr)\to\Rr\,\text{that commute with affine and bounds-check}\,t\}
\]
We get the set of probability distributions on \(X\)!  Here, their interface is
through expectation values; it's easy enough to recover masses: just take
expectations of functions that are \(1\) or \(0\) according to whether we are
inside or outside the set whose mass we want.
<p>
When \(X\) is infinite, we modify definitions to allow \(\epsilon\)'s domain
to be a nice subset of \(X\to\Rr\); this is how we get around the fact that some
functions have no expectation values.<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160for example, look up Banach-Tarski paradox</span></span>
<p>
Cute summary: to start, \(\epsilon\) stood for <em>evaluation</em>;
now it stands for <em>expectation</em>.  More content-fully:
\[
\texttt{randomvaluein}\,X
\cong
\{
\epsilon:\fF\to\Rr\,\text{affine and positive}
\}
\qquad
\fF\subseteq (X\to\Rr)
\]
Here, \(\fF\) is extra data associated with \(X\) and suppressed in our
notation.  It tells us the set of functions we are allowed to take expectations
of.  Mathematically, \(\fF\) can be anything closed under our
affine-combination and bounds-check transforms.  Which \(\fF\) we choose
depends on the situation we're analyzing.  But in practice only familiar
\(\fF\)s show up, the kind we don't need to think about because we're only
taking expectations of friendly rather than pathological functions.
<p>
<p>
<h5>  Dis-integration ; Conditional and Marginal </h5>
<h5>  Independence and Averaging </h5>
<h5>  Moments and Cumulants </h5>
<h5>  Aside on Concentration </h5>
<p>
<h5>  Example densities: the Student-t family </h5>
Consider the <b>student-t</b> family of (unnormalized) densities<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160Use limits to
define the density at special values of \(a\): \(y^\epsilon\to{1}\) and
\((1+\epsilon y)^{1/\epsilon}\to\exp(y)\).</span></span>
\[
p(x) \propto \frac{1}{\sqrt{1+ax^2}^{1+1/a}}
\]
This is defined on
for \(|x|\leq{1/\sqrt{{}|a|{}}}\) when \(a\) is negative and
on the whole real line when \(a\) is non-negative.  It is always normalizable.
<p>
The parameter \(a\) tells us how much heavier the tail is than a Gaussian:
\(a\lt{0}\) gives bounded distributions,
\(a\gt{0}\) gives power-law tails, and
\(a=0\) gives a Gaussian.
If we take \(a\to-\infty\) while horizontally and vertically scaling
appropriately, we get the Jeffries distribution \(p(x)\propto\sqrt{(1-x)(1+x)}\).
If we take \(a\to+\infty\) while horizontally and vertically scaling
appropriately, we get an unnormalizable Coulomb distribution
\(p(x)\propto{}1/|x|\).
<p>
In summary:
\[
\underbrace{-\infty}_{\text{Jeffries}}
\quad\underbrace{-1}_{\text{uniform}}
\quad\underbrace{-1/2}_{\text{semi-circle}}
\quad\underbrace{0}_{\text{normal}}
\quad\underbrace{+1/2}_{\text{minimal student}}
\quad\underbrace{+1}_{\text{Cauchy}}
\quad\underbrace{+\infty}_{\text{Coulomb}}
\]
A "minimal student" aka "3-point student" variable<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160up to scaling by
\(\sqrt{n/(n-1)}\)</span></span> describes the standardized error
\((\mu-Mean)/\sqrt{Var/n}\) of our mean estimate, where we estimate Mean and
Variance from \(n=3\) samples, and the underlying distribution is Gaussian.
The sample-size \(n=3\) is interesting it is the smallest that exceeds the
number of unknown parameters \(\mu,\sigma^2\).
<p>
<h4>  Basic Physics </h4>
<h5>  Extremal Principles </h5>
<h6>  Expect Low Energies </h6>
Why do physics classes focus so much on <em>how things move</em>?  There's probably a
good reason, but I still find it fun to imagine an alternative: the physics of
<em>which configurations don't move</em>.  The key fact that allows us to make
quantitative predictions is this: <b>the universe is cold</b>!  So in many
situations may assume that energy is minimized;<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160I can't resist
mentioning a second (and
class-unrelated) extremal principle that says how things move when they <em>do</em>
move: the Principle of Least Action.  Google it for your general enrichment.
The two principles engage in a
profound analogy \(\text{energy}:\text{action}::1/T:-i/\hbar\) due to Dirac and
Feynman.
That is, quantum fluctuations obey the same equations as thermal fluctuations
when the temperature is Planck's constant times \(\sqrt{-1}\)!
</span></span>
this (helps us predict instability and) severely constrains the stable
configuration(s).
<p>
<h6>  High Energies are Exponentially Improbable </h6>
The leading order correction to the energy-minimizing picture is to quantify
how much more <em>improbable</em> high-energy configurations are than low-energy ones.
(I say "leading correction", since we neglect <em>how and on what</em> timescales
improbable configurations evolve to probable ones.) I will now spell
out the Key Formula; I'll thereby in 5 minutes teach you all of
statistical mechanics.
<p>
If \(Q\) collects together all the extensive conserved quantities (energy,
electric charge, etc) relevant to a physics situation, we posit that most
macroscopic quantities of interest end up being functions of \(Q\).
Suppose it makes sense to assign to each system \(X\) a size \(P_X(Q)\) of the
subset of \(X\)'s configurations that have the assigned value of \(Q\).
We posit that \(S = \log P\) is extensive in the sense that when we set
together, side-by, side two systems \(X,X\pr\) with negligible interactions,
then \(\log P_{X,X\pr}(Q,Q\pr) = \log P_X(Q) + \log P_{X\pr}(Q\pr)\).
Since \(S\) and \(Q\) are extensive, if we put together a large number \(M\) of similar
negligibly-interacting systems, then the overall \(S\) is the \(M\)-factor
convolution of the individual systems' \(S\)s.
Convolution of nice functions tends to make them smoother (think of central
limit theorem).  Let us assume, then, that \(S\) for large systems looks
smooth.
<p>
Say, now, that we have a system-of-interest \(X\) very-weakly interacting with
a huge "bath" \(B\).  We have \(Q_X+Q_B=Q_{X,B}\).  The "bath" is so big that
\(S_B(Q_B)\) is differentiable with respect to \(Q_B\), and is so much bigger
than \(X\) that this derivative is constant in the range of values \(Q_B\)
could take, and (say) equal to the derivative at the constant \(Q_{X,B}\).
Then
\[
    P_{X,B}(Q_X,Q_B)
    =
    P_X(Q_X) P_B(Q_B)
    =
    P_X(Q_X) \exp(S_B(Q_B))
\]
Now, estimating \(S_B(Q_B)\approx (\nabla S_B(Q_{X,B}))\cdot (Q_B-Q_{X,B})\),
we see
\[
    \cdots
    \propto
    P_X(Q_X) \exp(- (\nabla S_B(Q_{X,B}))\cdot Q_X)
\]
<p>
Two systems in equilibrium have the same \(\nabla S\)s.
<p>
<h6>  The Exponential Rates are Recognizable Quantities </h6>
There are common names for the components of \(\nabla S_X\) when our conserved
extensive quantities are Energy and Volume.  The partial along energy is
\(X\)'s <b>coldness</b> \(\beta\); it says how greedy \(X\) is for energy:
the colder \(X\) is, the more hungrily it yearns for any extra energy it can
snatch.  Coldness is so fundamental that we <em>define</em> <b>temperature</b> in terms of
coldness: \(T\triangleq{}1/\beta\).<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160For historical reasons there's a factor
called Boltzmann's constant, which from the microscopic physics perspective is
no more fundamental than the conversion constant from nanometers to yards.</span></span>
<p>
Likewise, the partial \(\gamma\) along volume is a kind of "expansiveness", or
greediness for volume.  It measures desire to expand.  We define <b>pressure</b> as
\(p\triangleq{}\gamma/\beta\).
\[
    \beta = \partial{S}/\partial{E}
    \qquad
    \gamma = \partial{S}/\partial{V}
    \qquad
    T \triangleq 1/\beta
    \qquad
    p \triangleq \gamma/\beta
\]
<p>
How does \(p\) relate to good ol' force-per-area?  Well, imagine putting \(X\)
into a piston with a sliding ceiling of area-\(A\) and weight \(mg\).<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160Do this
in a vacuum so that we can ignore squeezing from the atmosphere.  In
particular, the ceiling and external world's entropy is constant with respect
to the changes we consider.</span></span>  What's
the most probable ceiling height?  Well, lowering the ceiling by \(\Delta{h}\)
has two effects: the weight loses energy \(\Delta{E}=(mg\Delta h)\) to \(X\),
so \(S_X\) increases by \(\beta\Delta{E}\); and \(X\) loses volume
\(\Delta{V}=A\Delta h\), so \(S_X\) decreases by \(\gamma\Delta{V}\).  At the
most probable ceiling height, \(S_X\) is maximized, so the two changes have
to balance out:
\[
\beta\Delta{E} = \gamma\Delta{V}
\qquad
p\triangleq\gamma/\beta = \Delta{E}/\Delta{V} = mg/A
\]
We have recovered the force-per-area rule from our more fundamental statistical
picture.
<p>
By the way, note
\(p=(\partial{S}/\partial{V})_E/(\partial{S}/\partial{E})_V=-(\partial{E}/\partial{V})_S\).
<p>
<h6>  Example of the Ideal Gas </h6>
For a large number \(N\) free particles with no internal structure, the only
microscopic degrees of freedom are position and momentum.  What's the volume in
configuration space for given \(V=L^3\) and \(E\)?  Well, each of \(3N\)
position components ranges through a size-\(L\) interval; likewise, each of the
\(3N\) momentum components has on average \(\epsilon=E/(3N)\) much energy,
hence in effect ranges through an interval of size
\(\propto\sqrt{\epsilon/(2m)}\propto\sqrt{\epsilon}\).  Thus:
\[
S \approx 3N\log(L\sqrt{E/(3N)})
\]
whence \(T=(2/3)E/N\) and \(p=(2/3)E/(VN)\).  It follows
that<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160The usual conversion factor \(R\), as in our previous discussion of
Boltzmann's constant, is a historical accident stemming from early workers'
attachment to false scale symmetry.</span></span>
\[
pV=NT
\]
<p>
<p>
Due to this simple relationship, and because close-to-ideal-gases are for many
lab applications easily found, we can take the ideal gas behavior as giving an
alternative, experimentally-accessible definition of temperature (with
pressure=Force/area).
<p>
Let's compute the heat capacity of an ideal gas.  Since \(E=(3/2)NT\) we get
\(C\triangleq{}\partial{E}/\partial{T}=(3/2)N\).  More generally, when we have
a large number \(M\) of degrees of freedom, in each of which the energy
function is quadratic, then those d.o.f.s contribute \(M/2\) to the heat
capacity.  Here, we had \(M=3N\) since each particle contributes 3 quadratic
terms \(p_x^2/2m, p_y^2/2m, p_z^2/2m\) to the energy.  A hot crystal (ensemble
of ideal springs; assume hot so can ignore quantum) would have greater heat capacity because its energy has
twice as many quadratic terms per particle: 3 new ones for position adding to
the 3 old ones for momentum.
<p>
<p>
<p>
<p>
<p>
<h6>  Summary </h6>
So now you know all of statistical mechanics.  The rest consists of ingenious
math tricks for efficiently computing expectation values of various
quantities-of-interest with respect to the exponential probability measure we
constructed above.  But if you're okay doing calculations inefficiently --- the
way Archimedes did calculus --- then you've got everything you need to, for
instance, compute the heat capacity of a hot dielectric crystal<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160dielectric
means the electron degrees of freedom are less confusing and hot means we can
ignore quantum effects</span></span> or the percent atmospheric oxygenation at various
altitudes and temperatures (just plug in the gravitational potential for
different molecular weights).
<p>
<p>
<p>
<p>
<p>
<p>
<h6>  Warning<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160My viewpoint here comes from Feynman and Truesdell</span></span> </h6>
Remember that all this StatMech is but a simple model of Nature's
incomprehensible complexity.  It never <em>perfectly</em> applies.  Even worse, its
scope of reasonable application, though large, is tricky to spell out:
the notion of a system being "<em>close enough to equilibrium</em>" not only lacks
some measurement device to operationally define it but in fact also depends on
which questions one wants to answer!<sup><span class="gray">&#9679</span></sup><span class="aside"><span class="asideinner"><span class="gray">&#9679</span>&#160Then again,
Euclid's ideal triangles are absent from real life, and neither carpenter nor
cartographer can crisply delineate this ideal concept's range of applicability.
Despite this, flat plane geometry dramatically enhances our ability to solve
real-world problems.</span></span>
For example, a warehouse's pressurized steel can of chlorine gas is in
"equilibrium" if we want to analyze heat capacity but not if we want to analyze
corrosion (since eventually, the system will reach a truer equilibrium where
the can gets corroded and the gas escapes).
Fortunately, the 20th century supports this empirical fact about humans: that
through exposure to standard StatMech examples, STEM majors cultivate
good-enough of a gut instinct for StatMech's scope that their predictions end
up being numerous, correct, and useful.
<p>
The previous paragraph is an antidote to a common disease encountered in the
study of StatMech, namely the disease of extrapolating --- from formulas that
codify intuitions trained only on our everyday experience with ice cubes
and kettle steam --- to a cosmic philosophy of "Time's Universal Arrow" and
"Consciousness as an Entropy Engine" and "Anthropic Principles from a
Multiversal Probability Distribution".  One might say this disease reflects
excess enthusiasm.  I'd respond that the Nature we can measure deserves our
enthusiasm even more than the Nature we can't.  Let even those who bend cosmic
remember how richly wondrous phenomena pack into everyday experience.
Isn't there magic in a snowflake's melting?
<p>
<p>
<p>
<p>
<h5>  Applications to Markov Chain Monte Carlo </h5>
<p>
    </body>
</html>
